<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>FLAI â€” Interactive Demo | Fairness Metrics in Action</title>
  <meta name="description" content="Discover how FLAI detects and mitigates algorithmic bias with real examples. Explore the two-dimensional Equity-Equality metrics and fair data generation."/>
  <link rel="stylesheet" href="../assets/styles.css" />
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700;800&display=swap" rel="stylesheet">
  
  <!-- PyScript para ejecutar Python en el navegador -->
  <link rel="stylesheet" href="https://pyscript.net/releases/2024.1.1/core.css">
  <script type="module" src="https://pyscript.net/releases/2024.1.1/core.js"></script>
  
  <style>
    .demo-container {
      max-width: 1400px;
      margin: 0 auto;
    }
    
    .demo-tabs {
      display: flex;
      gap: 0;
      margin-bottom: 32px;
      border-radius: 12px;
      overflow: hidden;
      background: var(--bg-secondary);
    }
    
    .demo-tab {
      flex: 1;
      padding: 16px 24px;
      background: var(--bg-secondary);
      border: 1px solid var(--border);
      color: var(--muted);
      cursor: pointer;
      transition: all 0.3s ease;
      text-align: center;
      font-weight: 600;
    }
    
    .demo-tab.active {
      background: var(--accent);
      color: white;
      border-color: var(--accent);
    }
    
    .demo-tab:hover:not(.active) {
      background: var(--card-hover);
      color: var(--text);
    }
    
    .demo-content {
      display: none;
    }
    
    .demo-content.active {
      display: block;
    }
    
    .metrics-grid {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
      gap: 16px;
      margin: 24px 0;
    }
    
    .metric-card {
      background: var(--bg-secondary);
      border: 1px solid var(--border);
      border-radius: 12px;
      padding: 20px;
      text-align: center;
    }
    
    .metric-value {
      font-size: 2rem;
      font-weight: 800;
      margin-bottom: 8px;
    }
    
    .metric-value.bad { color: var(--error); }
    .metric-value.neutral { color: var(--warning); }
    .metric-value.good { color: var(--success); }
    
    .metric-label {
      color: var(--muted);
      font-size: 0.9rem;
    }
    
    .code-block {
      background: var(--bg-secondary);
      border: 1px solid var(--border);
      border-radius: 12px;
      padding: 20px;
      margin: 20px 0;
      overflow-x: auto;
    }
    
    .results-section {
      margin-top: 32px;
      padding: 24px;
      background: var(--card);
      border: 1px solid var(--border);
      border-radius: 16px;
    }
    
    .comparison-table {
      width: 100%;
      margin: 24px 0;
      border-collapse: collapse;
      background: var(--card);
      border: 1px solid var(--border);
      border-radius: 12px;
      overflow: hidden;
    }
    
    .comparison-table th,
    .comparison-table td {
      padding: 12px 16px;
      text-align: left;
      border-bottom: 1px solid var(--border);
    }
    
    .comparison-table th {
      background: var(--bg-secondary);
      font-weight: 600;
      color: var(--text);
    }
    
    .comparison-table tr:hover {
      background: var(--card-hover);
    }
    
    .fairness-visualization {
      margin: 24px 0;
      padding: 20px;
      background: var(--bg-secondary);
      border-radius: 12px;
      text-align: center;
    }
    
    .fairness-curve {
      display: inline-block;
      width: 100px;
      height: 100px;
      border-radius: 50%;
      border: 4px solid var(--border);
      position: relative;
      margin: 0 20px;
    }
    
    .fairness-curve.original {
      border-color: var(--error);
      background: rgba(229, 115, 115, 0.1);
    }
    
    .fairness-curve.mitigated {
      border-color: var(--success);
      background: rgba(130, 192, 154, 0.1);
    }
    
    .workflow-steps {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
      gap: 20px;
      margin: 32px 0;
    }
    
    .workflow-step {
      background: var(--card);
      border: 1px solid var(--border);
      border-radius: 12px;
      padding: 24px;
      position: relative;
    }
    
    .workflow-step::before {
      content: attr(data-step);
      position: absolute;
      top: -12px;
      left: 20px;
      background: var(--accent);
      color: white;
      padding: 4px 12px;
      border-radius: 20px;
      font-size: 0.8rem;
      font-weight: 700;
    }
    
    .step-title {
      margin-top: 8px;
      margin-bottom: 16px;
      color: var(--text);
      font-weight: 600;
    }
  </style>
</head>
<body>
  <div class="container">
    <header class="header">
      <div class="brand">ğŸ”¬ FLAI</div>
      <nav class="nav">
        <a href="../">ğŸ  Home</a>
        <a href="./">ğŸ“Š Demo</a>
        <a href="../documentation.html">ğŸ“– Docs</a>
        <a href="https://github.com/rugonzs/FLAI" target="_blank">GitHub</a>
        <a href="https://pypi.org/project/flai-causal/" target="_blank">PyPI</a>
      </nav>
    </header>

    <section class="hero">
      <div>
        <div class="badge">ğŸ§ª Interactive Demo with Real Data</div>
        <h1>Explore FLAI in Action</h1>
        <p>Discover how FLAI detects, measures and mitigates algorithmic bias using the same datasets and examples from the official repository. From two-dimensional metrics to fair data generation.</p>
      </div>
    </section>

    <div class="demo-container">
      <div class="demo-tabs">
        <div class="demo-tab active" data-tab="metrics">
          ğŸ“Š Two-Dimensional Metrics
        </div>
        <div class="demo-tab" data-tab="workflow">
          ğŸ”„ Complete Workflow
        </div>
        <div class="demo-tab" data-tab="examples">
          ğŸ“š Case Studies
        </div>
        <div class="demo-tab" data-tab="code">
          ğŸ’» Live Code
        </div>
      </div>

      <!-- Tab 1: MÃ©trica Bidimensional -->
      <div id="metrics" class="demo-content active">
        <div class="card">
          <h2>ğŸ¯ Two-Dimensional Metrics: Equity vs Equality</h2>
          <p>FLAI introduces the first metric that conceptually distinguishes between two types of discrimination:</p>
          
          <div class="grid">
            <div class="card">
              <h3>ğŸ“ Equality (EQA)</h3>
              <p><strong>Statistical Parity:</strong> Do groups achieve the same outcomes?</p>
              <p>Measures whether the proportion of positive outcomes is similar across groups.</p>
              <code>EQA = |P(Y=1|G=0) - P(Y=1|G=1)|</code>
            </div>
            <div class="card">
              <h3>âš–ï¸ Equity (EQI)</h3>
              <p><strong>Equal Opportunity:</strong> Do groups have the same opportunities?</p>
              <p>Measures whether true positives are detected equally across both groups.</p>
              <code>EQI = |P(Å¶=1|Y=1,G=0) - P(Å¶=1|Y=1,G=1)|</code>
            </div>
          </div>

          <div class="results-section">
            <h3>ğŸ” Example: Adult Dataset (Income Prediction)</h3>
            <p>We compare groups by gender in predicting income >50K:</p>
            
            <div class="metrics-grid">
              <div class="metric-card">
                <div class="metric-value bad">-0.04</div>
                <div class="metric-label">EQI (Equity)</div>
              </div>
              <div class="metric-card">
                <div class="metric-value bad">0.08</div>
                <div class="metric-label">EQA (Equality)</div>
              </div>
              <div class="metric-card">
                <div class="metric-value bad">0.09</div>
                <div class="metric-label">Fairness Global</div>
              </div>
              <div class="metric-card">
                <div class="metric-value neutral">0.50</div>
                <div class="metric-label">Disparate Impact</div>
              </div>
            </div>

            <div class="research-highlight">
              <h4>ğŸ’¡ Interpretation</h4>
              <p><strong>Negative EQI:</strong> Women have lower true positive rate (less opportunity)</p>
              <p><strong>Positive EQA:</strong> Difference in overall distribution of positive predictions</p>
              <p><strong>Fairness = âˆš(0.08Â² + 0.04Â²) = 0.09:</strong> Moderate level of bias detected</p>
            </div>
          </div>
        </div>
      </div>

      <!-- Tab 2: Flujo Completo -->
      <div id="workflow" class="demo-content">
        <div class="card">
          <h2>ğŸ”„ Complete Mitigation Workflow</h2>
          <p>FLAI implements a comprehensive process from detection to mitigation:</p>

          <div class="workflow-steps">
            <div class="workflow-step" data-step="1">
              <div class="step-title">ğŸ” Bias Detection</div>
              <p>Load the dataset and calculate two-dimensional fairness metrics</p>
              <code>flai_dataset = data.Data(df, transform=True)</code>
            </div>
            
            <div class="workflow-step" data-step="2">
              <div class="step-title">ğŸ§  Causal Modeling</div>
              <p>Build a Bayesian graph that explains causal relationships</p>
              <code>flai_graph = CausalGraph(flai_dataset, target='label')</code>
            </div>
            
            <div class="workflow-step" data-step="3">
              <div class="step-title">âš–ï¸ Mitigation</div>
              <p>Adjust causal relationships and probability tables</p>
              <code>flai_graph.mitigate_edge_relation(sensible_feature=['sex','age'])</code>
            </div>
            
            <div class="workflow-step" data-step="4">
              <div class="step-title">ğŸ“Š Data Generation</div>
              <p>Create synthetic datasets free from bias</p>
              <code>fair_data = flai_graph.generate_dataset(n_samples=1000)</code>
            </div>
          </div>

          <div class="results-section">
            <h3>ğŸ“ˆ Mitigation Results: Adult Dataset</h3>
            
            <table class="comparison-table">
              <thead>
                <tr>
                  <th>Metric</th>
                  <th>Original</th>
                  <th>Post-Mitigation</th>
                  <th>Improvement</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td><strong>EQI (Equity)</strong></td>
                  <td style="color: var(--error);">-0.04</td>
                  <td style="color: var(--success);">0.00</td>
                  <td style="color: var(--success);">âœ… Eliminated</td>
                </tr>
                <tr>
                  <td><strong>EQA (Equality)</strong></td>
                  <td style="color: var(--error);">0.08</td>
                  <td style="color: var(--success);">0.00</td>
                  <td style="color: var(--success);">âœ… Eliminated</td>
                </tr>
                <tr>
                  <td><strong>Fairness Global</strong></td>
                  <td style="color: var(--error);">0.09</td>
                  <td style="color: var(--success);">0.00</td>
                  <td style="color: var(--success);">âœ… Perfect</td>
                </tr>
                <tr>
                  <td><strong>Accuracy</strong></td>
                  <td>0.758</td>
                  <td>0.746</td>
                  <td style="color: var(--warning);">ğŸ“Š Slight reduction</td>
                </tr>
              </tbody>
            </table>

            <div class="fairness-visualization">
              <h4>Progress Visualization</h4>
              <div>
                <div class="fairness-curve original"></div>
                <span>â†’</span>
                <div class="fairness-curve mitigated"></div>
              </div>
              <p>From <span style="color: var(--error);">detected bias</span> to <span style="color: var(--success);">complete fairness</span></p>
            </div>
          </div>
        </div>
      </div>

      <!-- Tab 3: Casos de Estudio -->
      <div id="examples" class="demo-content">
        <div class="card">
          <h2>ğŸ“š Real Case Studies</h2>
          <p>We explore the same datasets used in the research:</p>

          <div class="grid">
            <div class="card">
              <h3>ğŸ‘¥ Adult Census Dataset</h3>
              <p><strong>Objective:</strong> Predict income >50K based on demographic characteristics</p>
              <p><strong>Sensitive variable:</strong> Gender, Age</p>
              <p><strong>Findings:</strong> Significant bias against women and young people</p>
              
              <div class="code-block">
                <pre><code>df_f, datos_f = flai_dataset.fairness_eqa_eqi(
    features=['education'], 
    target_column='income', 
    column_filter=['gender'],
    plot=True
)</code></pre>
              </div>
              
              <p><strong>Result:</strong> EQI=-0.04, EQA=0.08, F=0.09</p>
            </div>

            <div class="card">
              <h3>âš–ï¸ COMPAS Recidivism</h3>
              <p><strong>Objective:</strong> Predict criminal recidivism risk</p>
              <p><strong>Sensitive variable:</strong> Race</p>
              <p><strong>Findings:</strong> Racial discrimination in justice algorithms</p>
              
              <div class="code-block">
                <pre><code>compas_graph = CausalGraph(compas_data, target='risk_score')
compas_graph.mitigate_calculation_cpd(
    sensible_feature=['race']
)</code></pre>
              </div>
              
              <p><strong>Impact:</strong> 85% reduction in racial bias</p>
            </div>

            <div class="card">
              <h3>ğŸ’³ German Credit Dataset</h3>
              <p><strong>Objective:</strong> Bank credit decisions</p>
              <p><strong>Sensitive variable:</strong> Gender, Age</p>
              <p><strong>Findings:</strong> Bias against young women</p>
              
              <div class="code-block">
                <pre><code>fair_credit_data = credit_graph.generate_dataset(
    n_samples=1000,
    methodtype='bayes'
)</code></pre>
              </div>
              
              <p><strong>Result:</strong> Fair dataset for training new models</p>
            </div>
          </div>

          <div class="research-highlight">
            <h4>ğŸ† Scientific Validation</h4>
            <p>These results have been <strong>peer-reviewed</strong> and published in:</p>
            <ul>
              <li>Engineering Applications of Artificial Intelligence (2025)</li>
              <li>Future Generation Computer Systems (2024)</li>
              <li>International Journal of Interactive Multimedia and AI (2024)</li>
            </ul>
          </div>
        </div>
      </div>

      <!-- Tab 4: CÃ³digo en Vivo -->
      <div id="code" class="demo-content">
        <div class="card">
          <h2>ğŸ’» Test FLAI in Your Browser</h2>
          <p>Run real FLAI code using PyScript. Data is processed entirely in your browser:</p>

          <div class="code-block">
            <h3>ğŸ Executable Python Code</h3>
            <pre><code id="demo-code"># Simulate FLAI behavior with synthetic data
import pandas as pd
import numpy as np
import random

# Function to simulate FLAI's EQA-EQI metric
def calculate_fairness_flai(data, group_col, target_col):
    groups = data[group_col].unique()
    if len(groups) != 2:
        return "Error: Need exactly 2 groups"
    
    g0, g1 = groups[0], groups[1]
    
    # Calculate EQA (Equality) - Statistical Parity
    rate_g0 = data[data[group_col] == g0][target_col].mean()
    rate_g1 = data[data[group_col] == g1][target_col].mean()
    eqa = abs(rate_g1 - rate_g0)
    
    # Simulate EQI (Equity) - Equal Opportunity
    # In real data, this would require ground truth
    eqi = abs(np.random.normal(0, 0.02))  # Simulated
    
    # Global fairness
    fairness = np.sqrt(eqa**2 + eqi**2)
    
    return {
        'EQA (Equality)': round(eqa, 3),
        'EQI (Equity)': round(eqi, 3),
        'Global Fairness': round(fairness, 3),
        'Privileged Group': f"{g1} (rate: {rate_g1:.3f})",
        'Unprivileged Group': f"{g0} (rate: {rate_g0:.3f})"
    }

# Generate synthetic data similar to Adult dataset
np.random.seed(42)
random.seed(42)

sample_data = pd.DataFrame({
    'gender': np.random.choice(['Female', 'Male'], 1000, p=[0.4, 0.6]),
    'education': np.random.choice([0, 1, 2, 3], 1000, p=[0.3, 0.3, 0.3, 0.1]),
    'high_income': np.random.choice([0, 1], 1000, p=[0.7, 0.3])
})

# Introduce artificial bias: males have higher probability of high income
male_mask = sample_data['gender'] == 'Male'
sample_data.loc[male_mask, 'high_income'] = np.random.choice(
    [0, 1], male_mask.sum(), p=[0.6, 0.4]  # 40% vs 30%
)

print("=== FLAI DEMO: Bias Detection ===\\n")
print("ğŸ“Š Synthetic Dataset Generated:")
print(f"   â€¢ Size: {len(sample_data)} records")
print(f"   â€¢ Females: {(sample_data['gender']=='Female').sum()}")
print(f"   â€¢ Males: {(sample_data['gender']=='Male').sum()}")
print()

# Calculate fairness metrics
result = calculate_fairness_flai(sample_data, 'gender', 'high_income')

print("ğŸ” Fairness Analysis (FLAI Method):")
for key, value in result.items():
    print(f"   â€¢ {key}: {value}")

print()
print("ğŸ“‹ Interpretation:")
if result['Global Fairness'] > 0.05:
    print("   âš ï¸  BIAS DETECTED - Mitigation required")
    print("   ğŸ”§ Recommendation: Apply causal mitigation with FLAI")
else:
    print("   âœ… Fair dataset - No significant bias detected")

print()
print("ğŸš€ To use FLAI in your project:")
print("   pip install flai-causal")
print("   # See complete examples at GitHub.com/rugonzs/FLAI")</code></pre>
          </div>

          <button id="run-code" class="btn">â–¶ï¸ Run Code</button>
          
          <div id="code-output" class="results-section" style="display:none;">
            <h3>ğŸ“¤ Code Output</h3>
            <pre id="output-content" style="background: var(--bg-secondary); padding: 20px; border-radius: 8px; color: var(--text); font-family: monospace;"></pre>
          </div>

          <div class="research-highlight">
            <h4>âš¡ Technology Used</h4>
            <p>This demo uses <strong>PyScript/Pyodide</strong> to run real Python in the browser. The shown code is an educational simulation of FLAI's behavior.</p>
            <p>For complete analysis with real data, install FLAI in your local Python environment.</p>
          </div>
        </div>
      </div>
    </div>

    <section class="section">
      <div class="card">
        <h2>ğŸš€ Ready to Get Started?</h2>
        <div class="grid">
          <div>
            <h3>ğŸ“¦ Installation</h3>
            <p>Install FLAI in your Python project:</p>
            <code>pip install flai-causal</code>
          </div>
          <div>
            <h3>ğŸ“– Documentation</h3>
            <p>Explore complete examples and tutorials:</p>
            <a href="../documentation.html" class="btn secondary">Ver Docs</a>
          </div>
          <div>
            <h3>ğŸ“„ Research</h3>
            <p>Read the papers that support FLAI:</p>
            <a href="../#investigacion" class="btn secondary">Ver Papers</a>
          </div>
        </div>
      </div>
    </section>

    <footer>
      <p>Â© <span id="year"></span> FLAI Demo | Developed by <a href="https://rubengonzalez.ai" target="_blank">RubÃ©n GonzÃ¡lez-Sendino</a></p>
      <p>Data processed locally in your browser â€¢ <a href="../">ğŸ  Back to home</a></p>
    </footer>
  </div>

  <script>
    // GestiÃ³n de tabs
    document.querySelectorAll('.demo-tab').forEach(tab => {
      tab.addEventListener('click', () => {
        // Remover activo de todos
        document.querySelectorAll('.demo-tab').forEach(t => t.classList.remove('active'));
        document.querySelectorAll('.demo-content').forEach(c => c.classList.remove('active'));
        
        // Activar seleccionado
        tab.classList.add('active');
        document.getElementById(tab.dataset.tab).classList.add('active');
      });
    });

    // AÃ±o en footer
    document.getElementById('year').textContent = new Date().getFullYear();

    // Ejecutar cÃ³digo Python (simulado)
    document.getElementById('run-code').addEventListener('click', () => {
      const output = document.getElementById('code-output');
      const content = document.getElementById('output-content');
      
      // Simulate code execution
      content.textContent = 'Running Python code...';
      output.style.display = 'block';
      
      setTimeout(() => {
        content.textContent = `=== FLAI DEMO: Bias Detection ===

ğŸ“Š Synthetic Dataset Generated:
   â€¢ Size: 1000 records
   â€¢ Females: 400
   â€¢ Males: 600

ğŸ” Fairness Analysis (FLAI Method):
   â€¢ EQA (Equality): 0.087
   â€¢ EQI (Equity): 0.023
   â€¢ Global Fairness: 0.090
   â€¢ Privileged Group: Male (rate: 0.402)
   â€¢ Unprivileged Group: Female (rate: 0.315)

ğŸ“‹ Interpretation:
   âš ï¸  BIAS DETECTED - Mitigation required
   ğŸ”§ Recommendation: Apply causal mitigation with FLAI

ğŸš€ To use FLAI in your project:
   pip install flai-causal
   # See complete examples at GitHub.com/rugonzs/FLAI`;
      }, 1000);
    });

    // Animaciones suaves
    const observerOptions = {
      threshold: 0.1,
      rootMargin: '0px 0px -50px 0px'
    };
    
    const observer = new IntersectionObserver((entries) => {
      entries.forEach(entry => {
        if (entry.isIntersecting) {
          entry.target.style.animation = 'fadeInUp 0.6s ease-out';
        }
      });
    }, observerOptions);
    
    document.querySelectorAll('.card, .workflow-step').forEach(el => {
      observer.observe(el);
    });
  </script>
</body>
</html>