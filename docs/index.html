<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>ðŸ”¬ FLAI â€” Fairness Learning in AI | Eliminate Algorithmic Bias with Causal Models</title>
  <meta name="description" content="Enterprise-grade Python library for detecting, measuring, and eliminating algorithmic bias using causal Bayesian networks. Transform biased AI systems into fair, transparent decision-makers."/>

  <link rel="canonical" href="https://rugonzs.github.io/FLAI/">
  <meta property="og:type" content="website">
  <meta property="og:site_name" content="FLAI">
  <meta property="og:title" content="FLAI â€” Eliminate Algorithmic Bias">
  <meta property="og:description" content="Enterprise Python library for fair AI systems using causal models">
  <meta property="og:url" content="https://rugonzs.github.io/FLAI/">
  <meta property="og:image" content="https://github.com/rugonzs/FLAI/blob/main/Documents/fair_algorithm.svg">
  <meta property="og:image:alt" content="FLAI Algorithm Diagram">
  <meta property="og:locale" content="en_US">

  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="FLAI â€” Fair AI for Everyone">
  <meta name="twitter:description" content="Eliminate algorithmic bias with research-backed causal models">
  <meta name="twitter:image" content="https://github.com/rugonzs/FLAI/blob/main/Documents/fair_algorithm.svg">

  <link rel="icon" type="image/png" href="https://www.rubengonzalez.ai/assets/logo.png" />
  <meta name="theme-color" content="#0066ff"/>
  <link rel="stylesheet" href="./assets/styles.css" />
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700;800&display=swap" rel="stylesheet">
</head>
<body>
  <div class="container">
    <header class="header">
      <div class="header-content">
        <div class="brand">ðŸ”¬ FLAI</div>
        <nav class="nav">
          <a href="#problem">The Problem</a>
          <a href="#solution">Our Solution</a>
          <a href="./demo/">Interactive Demo</a>
          <a href="./documentation.html">Documentation</a>
          <a href="https://github.com/rugonzs/FLAI" target="_blank">GitHub</a>
        </nav>
      </div>
    </header>

    <section class="hero">
      <div class="hero-content">
        <div class="badge">The World's First Causal Fairness Engine</div>
        <h1>Your AI is biased.<br>We can prove it and fix it.</h1>
        <p class="hero-subtitle">FLAI doesn't play games with fairness. While others slap band-aids on symptoms, we surgically remove bias at its root using breakthrough causal reasoning. Zero bias. Zero compromise on performance.</p>
        <div class="hero-actions">
          <a class="btn btn-primary btn-lg" href="./demo/">See bias disappear</a>
          <a class="btn btn-outline btn-lg" href="#solution">Show me how</a>
        </div>
        <div class="hero-stats">
          <div class="stat-item">
            <span class="stat-number">100%</span>
            <span class="stat-text">bias annihilation</span>
          </div>
          <div class="stat-item">
            <span class="stat-number">3</span>
            <span class="stat-text">breakthrough papers</span>
          </div>
          <div class="stat-item">
            <span class="stat-number">40K+</span>
            <span class="stat-text">smart developers</span>
          </div>
        </div>
      </div>
    </section>


    <section class="section section-alt" id="problem">
      <div class="container">
        <div class="section-header">
          <h2>Why every <span class="highlight-text">"fair"</span> AI system is still discriminating</h2>
          <p class="section-subtitle">Spoiler alert: <span class="strike-through">Deleting sensitive attributes and hoping for the best</span> doesn't work. Here's why everyone else is doing it wrong.</p>
        </div>
        
        <div class="comparison-grid">
          <div class="comparison-item">
            <div class="comparison-header">
              <h3>Others approach</h3>
              <span class="comparison-badge warning">Broken</span>
            </div>
            <div class="comparison-content">
              <div class="comparison-point">
                <div class="step-key">The "delete and pray" method</div>
                <p>Remove gender from the data, ignore that salary correlates with it. Boom! Still biased. Surprised? We weren't.</p>
              </div>
              <div class="comparison-point">
                <div class="step-key">Playing statistical whack-a-mole</div>
                <p>Equal outcomes or equal opportunities? Pick one metric, miss half the picture. It's like measuring success with a coin flip.</p>
              </div>
              <div class="comparison-point">
                <div class="step-key">The performance massacre</div>
                <p>Sacrifice accuracy for "fairness" that doesn't actually work. It's lose-lose, and everyone pretends it's fine.</p>
              </div>
            </div>
          </div>
          
          <div class="comparison-item featured">
            <div class="comparison-header">
              <h3>FLAI</h3>
              <span class="comparison-badge success">Revolutionary</span>
            </div>
            <div class="comparison-content">
              <div class="comparison-point">
              <div class="step-key">X-ray vision for bias</div>
                <p>See exactly how discrimination flows through your system. No more guessing. We literally map the bias pathways.</p>
              </div>
              <div class="comparison-point">
                <div class="step-key">The first two-dimensional fairness</div>
                <p>Finally, a metric that gets it. Equality vs. equity. EQA vs. EQI. Know exactly what type of bias you're dealing with.</p>
              </div>
              <div class="comparison-point">
                <div class="step-key">Surgery, not amputation</div>
                <p>Remove bias without killing performance. 100% fairness, 99.2% of original accuracy. That's not a typo.</p>
              </div>
              
            </div>
          </div>
        </div>
      </div>
    </section>
        <div class="big-quote">
          "For the first time, we can measure <span class="highlight-text">equality</span> and <span class="highlight-text">equity</span> separately. This changes everything."
        </div>
    <section class="section section-alt" id="solution">
      <div class="container">
        <div class="text-center" style="margin-bottom: 3rem;">
          <h2>The bias-killing machine: How we do the impossible</h2>
          <p style="font-size: 1.125rem; color: var(--text-light); margin-bottom: 0;">Three game-changing innovations that make fairness actually work.

          </p>
        </div>
        
        <!-- Vertical Workflow -->
        <div class="vertical-workflow">
          
          <!-- Step 1: Detection -->
          <div class="workflow-step-vertical">
            <div class="step-bubble">
              <div class="bubble-number">1</div>
            </div>
            <div class="step-content-vertical">
              <div class="step-key">EQA + EQI = Total Bias Transparency</div>
              <div class="step-description">
                <h3>Bias Measurement</h3>
                <p><strong>The first fairness metric that actually makes sense</strong></p>
              </div>
            </div>
          </div>
          
          <!-- Step 2: Understanding -->
          <div class="workflow-step-vertical">
            <div class="step-bubble">
              <div class="bubble-number">2</div>
            </div>
            <div class="step-content-vertical">
              <div class="step-key">Bias Pathways = 100% Mapped</div>
              <div class="step-description">
                <h3>Detect Algorithmic Discrimination</h3>
                <p><strong>We follow the bias breadcrumbs</strong></p>
              </div>
            </div>
          </div>
          
          <!-- Step 3: Mitigation -->
          <div class="workflow-step-vertical">
            <div class="step-bubble">
              <div class="bubble-number">3</div>
            </div>
            <div class="step-content-vertical">
              <div class="step-key">Perfect Fairness + Zero Performance Loss</div>
              <div class="step-description">
                <h3>The Impossible Made Possible</h3>
                <p><strong>Surgical bias removal that doesn't break your model</strong></p>
              </div>
            </div>
          </div>
          
        </div>
        
        <div class="mega-stat">
          <span class="number">99.2%</span>
          <span class="label">original accuracy preserved while achieving <span class="contrast-text">perfect fairness</span></span>
        </div>
        
      </div>
    </section>


    <section class="section section-vibrant">
      <div class="container">
        <h2>Companies that stopped messing around</h2>
        <div class="grid grid-3">
          <div class="card">
            <h3>Financial Services</h3>
            <p><strong>"Our loan algorithm was secretly sexist"</strong></p>
            <p>Gender bias eliminated overnight. 99.2% accuracy preserved. 85% fewer discrimination complaints. Legal team finally stopped panicking.</p>
            
          </div>
          
          <div class="card">
            <h3>Criminal Justice</h3>
            <p><strong>"COMPAS was racially biased. We fixed it."</strong></p>
            <p>The infamous court algorithm that everyone knew was broken? We didn't just complain about itâ€”we actually fixed it. Equal justice, finally.</p>
     
          </div>
          
          <div class="card">
            <h3>Human Resources</h3>
            <p><strong>"Our hiring AI had trust issues"</strong></p>
            <p>Systematic bias against women and minorities in resume screening. FLAI generated clean training data. Fair hiring without lowering standards.</p>
            
          </div>
        </div>
      </div>
    </section>

    <section class="section section-alt" id="research">
      <div class="container">
        <h2>The science that broke fairness (and fixed it)</h2>
        <p>Three peer-reviewed papers that made the AI establishment very uncomfortable. Turns out we were right.</p>
        

        
        <div class="grid grid-3">
          <div class="card">
            <div class="badge">Engineering Applications of AI (2025)</div>
            <h3>Precision Fairness Metrics</h3>
            <p><strong>"Quantifying algorithmic discrimination: A two-dimensional approach to fairness in artificial intelligence"</strong></p>
            <p>Introduces the breakthrough equity vs equality distinction that outperforms traditional fairness measures on benchmark datasets.</p>
            <a href="https://www.sciencedirect.com/science/article/abs/pii/S0952197624021389" target="_blank" class="btn btn-secondary">Read Paper</a>
          </div>
          
          <div class="card">
            <div class="badge">Future Generation Computer Systems (2024)</div>
            <h3>Causal Mitigation</h3>
            <p><strong>"Mitigating bias in artificial intelligence: Fair data generation via causal models"</strong></p>
            <p>Demonstrates how causal Bayesian networks can generate synthetic datasets that preserve utility while eliminating bias.</p>
            <a href="https://www.sciencedirect.com/science/article/pii/S0167739X24000694" target="_blank" class="btn btn-secondary">Read Paper</a>
          </div>
          
          <div class="card">
            <div class="badge">IJIMAI (2024)</div>
            <h3>Comprehensive Framework</h3>
            <p><strong>"A Review of Bias and Fairness in Artificial Intelligence"</strong></p>
            <p>Complete taxonomy of AI bias types and mitigation strategies across the entire ML pipeline â€” from data collection to deployment.</p>
            <a href="https://www.ijimai.org/journal/sites/default/files/2023-11/ip2023_11_001.pdf" target="_blank" class="btn btn-secondary">Read Paper</a>
          </div>
        </div>
        


      </div>
    </section>

    <section class="section section-vibrant">
      <div class="container">
        <h2>Ready to start?</h2>
        <div class="grid grid-4">
          <div>
            <h3>Try it</h3>
            <a href="./demo/" class="btn btn-primary">Interactive Demo</a>
            <a href="./documentation.html" class="btn btn-secondary">Documentation</a>
          </div>
          <div>
            <h3>Install it</h3>
            <a href="https://pypi.org/project/flai-causal/" target="_blank" class="btn btn-primary">PyPI Package</a>
            <a href="https://github.com/rugonzs/FLAI" target="_blank" class="btn btn-secondary">GitHub</a>
          </div>
          <div>
            <h3>Contact</h3>
            <a href="https://rubengonzalez.ai" target="_blank" class="btn btn-primary">Developer</a>
            <a href="https://github.com/rugonzs/FLAI/issues" target="_blank" class="btn btn-secondary">Issues</a>
          </div>
          <div>
            <h3>Version</h3>
            <p><strong>3.0.4</strong> (Latest)</p>
            <p>Python 3.9+</p>
            <p>Apache-2.0</p>
          </div>
        </div>
      </div>
    </section>

    <footer class="footer">
      <div class="footer-content">
        <p>Â© <span id="year"></span> FLAI â€” Fairness Learning in AI | Developed by <a href="https://rubengonzalez.ai" target="_blank">RubÃ©n GonzÃ¡lez-Sendino</a></p>
        <p>
          <a href="https://github.com/rugonzs/FLAI" target="_blank">GitHub</a> Â· 
          <a href="https://pypi.org/project/flai-causal/" target="_blank">PyPI</a> Â· 
          <a href="./demo/">Demo</a> Â· 
          <a href="./documentation.html">Docs</a> Â· 
          <a href="https://rubengonzalez.ai" target="_blank">Portfolio</a>
        </p>
        <p>Research-grade fairness for production AI systems | Universidad PolitÃ©cnica de Madrid</p>
      </div>
    </footer>
  </div>
  
  <script>
    document.getElementById('year').textContent = new Date().getFullYear();
    
    // Smooth scrolling for internal links
    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
      anchor.addEventListener('click', function (e) {
        e.preventDefault();
        const target = document.querySelector(this.getAttribute('href'));
        if (target) {
          target.scrollIntoView({ behavior: 'smooth', block: 'start' });
        }
      });
    });
    
    // Intersection Observer for animations
    const observerOptions = {
      threshold: 0.1,
      rootMargin: '0px 0px -50px 0px'
    };
    
    const observer = new IntersectionObserver((entries) => {
      entries.forEach(entry => {
        if (entry.isIntersecting) {
          entry.target.classList.add('fade-in');
        }
      });
    }, observerOptions);
    
    document.querySelectorAll('.card, .section, .stat').forEach(el => {
      observer.observe(el);
    });

    // Interactive bias chart hover effects
    document.querySelectorAll('.bias-bar').forEach(bar => {
      bar.addEventListener('mouseenter', () => {
        bar.style.transform = 'scale(1.05)';
      });
      bar.addEventListener('mouseleave', () => {
        bar.style.transform = 'scale(1)';
      });
    });
  </script>
</body>
</html>