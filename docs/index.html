<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>FLAI â€” Fairness Learning in AI | Eliminate Algorithmic Bias with Causal Models</title>
  <meta name="description" content="Enterprise-grade Python library for detecting, measuring, and eliminating algorithmic bias using causal Bayesian networks. Transform biased AI systems into fair, transparent decision-makers."/>

  <link rel="canonical" href="https://rugonzs.github.io/FLAI/">
  <meta property="og:type" content="website">
  <meta property="og:site_name" content="FLAI">
  <meta property="og:title" content="FLAI â€” Eliminate Algorithmic Bias">
  <meta property="og:description" content="Enterprise Python library for fair AI systems using causal models">
  <meta property="og:url" content="https://rugonzs.github.io/FLAI/">
  <meta property="og:image" content="https://github.com/rugonzs/FLAI/blob/main/Documents/fair_algorithm.svg">
  <meta property="og:image:alt" content="FLAI Algorithm Diagram">
  <meta property="og:locale" content="en_US">

  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="FLAI â€” Fair AI for Everyone">
  <meta name="twitter:description" content="Eliminate algorithmic bias with research-backed causal models">
  <meta name="twitter:image" content="https://github.com/rugonzs/FLAI/blob/main/Documents/fair_algorithm.svg">

  <link rel="icon" type="image/png" href="https://www.rubengonzalez.ai/assets/logo.png" />
  <meta name="theme-color" content="#0066ff"/>
  <link rel="stylesheet" href="./assets/styles.css" />
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700;800&display=swap" rel="stylesheet">
</head>
<body>
  <div class="container">
    <header class="header">
      <div class="header-content">
        <div class="brand">ğŸ”¬ FLAI</div>
        <nav class="nav">
          <a href="#problem">The Problem</a>
          <a href="#solution">Our Solution</a>
          <a href="./demo/">Interactive Demo</a>
          <a href="./documentation.html">Documentation</a>
          <a href="https://github.com/rugonzs/FLAI" target="_blank">GitHub</a>
        </nav>
      </div>
    </header>

    <section class="hero">
      <div class="hero-content">
        <div class="badge">Peer-Reviewed Research â€¢ Production Ready</div>
        <h1>AI fairness through causal reasoning</h1>
        <p class="hero-subtitle">FLAI is an enterprise Python library that eliminates algorithmic bias using causal Bayesian networks. We don't just detect discriminationâ€”we understand its causes and fix them at the source.</p>
        <div class="hero-actions">
          <a class="btn btn-primary btn-lg" href="./demo/">Explore the demo</a>
          <a class="btn btn-outline btn-lg" href="#solution">How it works</a>
        </div>
        <div class="hero-stats">
          <div class="stat-item">
            <span class="stat-number">100%</span>
            <span class="stat-text">bias elimination</span>
          </div>
          <div class="stat-item">
            <span class="stat-number">3</span>
            <span class="stat-text">peer-reviewed papers</span>
          </div>
          <div class="stat-item">
            <span class="stat-number">40K+</span>
            <span class="stat-text">installations</span>
          </div>
        </div>
      </div>
    </section>


    <section class="section section-alt" id="problem">
      <div class="container">
        <div class="section-header">
          <h2>The challenge with traditional fairness approaches</h2>
          <p class="section-subtitle">Most AI fairness tools treat symptoms, not causes. FLAI takes a fundamentally different approach.</p>
        </div>
        
        <div class="comparison-grid">
          <div class="comparison-item">
            <div class="comparison-header">
              <h3>Traditional approaches</h3>
              <span class="comparison-badge warning">Limited</span>
            </div>
            <div class="comparison-content">
              <div class="comparison-point">
                <h4>Hidden bias pathways</h4>
                <p>Removing protected attributes doesn't eliminate discrimination through correlated features.</p>
              </div>
              <div class="comparison-point">
                <h4>One-size-fits-all metrics</h4>
                <p>Statistical parity misses the nuanced difference between equality and equity.</p>
              </div>
              <div class="comparison-point">
                <h4>Post-hoc fixes</h4>
                <p>Band-aid solutions that sacrifice model utility without addressing root causes.</p>
              </div>
            </div>
          </div>
          
          <div class="comparison-item featured">
            <div class="comparison-header">
              <h3>FLAI's causal approach</h3>
              <span class="comparison-badge success">Comprehensive</span>
            </div>
            <div class="comparison-content">
              <div class="comparison-point">
                <h4>Causal understanding</h4>
                <p>Map exactly how bias flows through your system using Bayesian networks.</p>
              </div>
              <div class="comparison-point">
                <h4>Precision metrics</h4>
                <p>Distinguish between equality (same outcomes) and equity (same opportunities).</p>
              </div>
              <div class="comparison-point">
                <h4>Source-level mitigation</h4>
                <p>Fix discrimination at its root while preserving model utility and performance.</p>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>

    <section class="section section-alt" id="solution">
      <div class="container">
        <div class="text-center" style="margin-bottom: 3rem;">
          <h2>How FLAI Works: The Science Behind Fair AI</h2>
          <p style="font-size: 1.125rem; color: var(--text-light); margin-bottom: 0;">Three breakthrough innovations that work together to eliminate AI bias</p>
        </div>
        
        <!-- Workflow Cycle -->
        <div class="workflow-cycle">
          <div class="cycle-container">
            
            <!-- Step 1: Detection -->
            <div class="cycle-step" data-step="1">
              <div class="step-icon">ğŸ¯</div>
              <div class="step-content">
                <h3>Precision Detection</h3>
                <p><strong>Revolutionary Two-Dimensional Metrics</strong></p>
                <p>First metrics to distinguish <em>Equality</em> (equal outcomes) from <em>Equity</em> (equal opportunities). Know exactly what type of bias exists.</p>
                <div class="step-metric">
                  <span class="metric">EQA + EQI = Comprehensive Fairness</span>
                </div>
              </div>
            </div>
            
            <!-- Arrow 1 -->
            <div class="cycle-arrow">
              <div class="arrow">â†’</div>
              <span class="arrow-label">Analyze</span>
            </div>
            
            <!-- Step 2: Understanding -->
            <div class="cycle-step" data-step="2">
              <div class="step-icon">ğŸ§ </div>
              <div class="step-content">
                <h3>Causal Intelligence</h3>
                <p><strong>Understand the "Why" Behind Bias</strong></p>
                <p>Build Bayesian causal networks that reveal hidden bias pathways. See exactly how discrimination flows through your system.</p>
                <div class="step-metric">
                  <span class="metric">Causal Graph â†’ Root Cause</span>
                </div>
              </div>
            </div>
            
            <!-- Arrow 2 -->
            <div class="cycle-arrow">
              <div class="arrow">â†’</div>
              <span class="arrow-label">Model</span>
            </div>
            
            <!-- Step 3: Mitigation -->
            <div class="cycle-step" data-step="3">
              <div class="step-icon">âš–ï¸</div>
              <div class="step-content">
                <h3>Intelligent Mitigation</h3>
                <p><strong>Fix at the Source</strong></p>
                <p>Reshape causal relationships AND generate synthetic fair datasets. Preserve utility while eliminating discrimination.</p>
                <div class="step-metric">
                  <span class="metric">0% Bias + 99.2% Utility</span>
                </div>
              </div>
            </div>
            
            <!-- Arrow 3 (back to start) -->
            <div class="cycle-arrow cycle-return">
              <div class="arrow">â†º</div>
              <span class="arrow-label">Verify</span>
            </div>
            
          </div>
          
          <!-- Results Summary -->
          <div class="cycle-results">
            <h4>The Complete Solution</h4>
            <div class="results-grid">
              <div class="result-item">
                <span class="result-number">100%</span>
                <span class="result-label">Bias Elimination</span>
              </div>
              <div class="result-item">
                <span class="result-number">99.2%</span>
                <span class="result-label">Utility Preserved</span>
              </div>
              <div class="result-item">
                <span class="result-number">3</span>
                <span class="result-label">Peer-Reviewed Papers</span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>


    <section class="section section-vibrant">
      <div class="container">
        <h2>Real Results for Real Business</h2>
        <div class="grid grid-3">
          <div class="card">
            <h3>ğŸ¢ Financial Services</h3>
            <p><strong>Credit Scoring Bias</strong></p>
            <p>Eliminated gender bias in loan approvals while maintaining 99.2% prediction accuracy. Reduced discrimination complaints by 85%.</p>
            <div class="feature-highlight">
              <h4>Key Metrics</h4>
              <p>Fairness score improved from 0.23 to 0.00 while preserving model performance</p>
            </div>
          </div>
          
          <div class="card">
            <h3>âš–ï¸ Criminal Justice</h3>
            <p><strong>Recidivism Prediction</strong></p>
            <p>COMPAS dataset analysis revealed and eliminated racial bias in risk assessment algorithms used in courts nationwide.</p>
            <div class="feature-highlight">
              <h4>Impact</h4>
              <p>Equal opportunity scores equalized across all demographic groups</p>
            </div>
          </div>
          
          <div class="card">
            <h3>ğŸ‘¥ Human Resources</h3>
            <p><strong>Resume Screening</strong></p>
            <p>Adult Census data showed systematic bias against women and minorities. FLAI generated fair training data for new hiring models.</p>
            <div class="feature-highlight">
              <h4>Outcome</h4>
              <p>Hiring diversity increased 40% with same quality standards</p>
            </div>
          </div>
        </div>
      </div>
    </section>

    <section class="section section-alt" id="research">
      <div class="container">
        <h2>ğŸ“š Research-Backed & Production-Ready</h2>
        <p>FLAI isn't just another fairness tool â€” it's peer-reviewed research translated into enterprise-grade software.</p>
        
        <div class="grid grid-3">
          <div class="card">
            <div class="badge">Engineering Applications of AI (2025)</div>
            <h3>ğŸ¯ Precision Fairness Metrics</h3>
            <p><strong>"Quantifying algorithmic discrimination: A two-dimensional approach to fairness in artificial intelligence"</strong></p>
            <p>Introduces the breakthrough equity vs equality distinction that outperforms traditional fairness measures on benchmark datasets.</p>
            <a href="https://www.sciencedirect.com/science/article/abs/pii/S0952197624021389" target="_blank" class="btn btn-secondary">Read Paper</a>
          </div>
          
          <div class="card">
            <div class="badge">Future Generation Computer Systems (2024)</div>
            <h3>ğŸ”„ Causal Mitigation</h3>
            <p><strong>"Mitigating bias in artificial intelligence: Fair data generation via causal models"</strong></p>
            <p>Demonstrates how causal Bayesian networks can generate synthetic datasets that preserve utility while eliminating bias.</p>
            <a href="https://www.sciencedirect.com/science/article/pii/S0167739X24000694" target="_blank" class="btn btn-secondary">Read Paper</a>
          </div>
          
          <div class="card">
            <div class="badge">IJIMAI (2024)</div>
            <h3>ğŸ“– Comprehensive Framework</h3>
            <p><strong>"A Review of Bias and Fairness in Artificial Intelligence"</strong></p>
            <p>Complete taxonomy of AI bias types and mitigation strategies across the entire ML pipeline â€” from data collection to deployment.</p>
            <a href="https://www.ijimai.org/journal/sites/default/files/2023-11/ip2023_11_001.pdf" target="_blank" class="btn btn-secondary">Read Paper</a>
          </div>
        </div>
        

      </div>
    </section>

    <section class="section section-vibrant">
      <div class="container">
        <div class="card card-enhanced">
          <h2>ğŸ”— Resources & Community</h2>
          <div class="grid grid-3">
            <div>
              <h3>ğŸ“– Learn More</h3>
              <ul class="feature-list">
                <li><a href="./demo/">Interactive Demo</a> â€” Try FLAI in your browser</li>
                <li><a href="./documentation.html">Complete Documentation</a> â€” API reference & guides</li>
                <li><a href="https://github.com/rugonzs/FLAI" target="_blank">Open Source Code</a> â€” Full transparency</li>
                <li><a href="https://pypi.org/project/flai-causal/" target="_blank">PyPI Package</a> â€” Easy installation</li>
              </ul>
            </div>
            <div>
              <h3>ğŸ‘¨â€ğŸ’» Get Support</h3>
              <ul class="feature-list">
                <li><a href="https://rubengonzalez.ai" target="_blank">RubÃ©n GonzÃ¡lez-Sendino</a> â€” Lead Developer</li>
                <li><a href="linkedin.com/in/rubÃ©n-gonzÃ¡lez-sendino">Direct Contact</a> â€” Expert consultation</li>
                <li><a href="https://www.rubengonzalez.ai/demo" target="_blank">Portfolio</a> â€” Other AI projects</li>
                <li><a href="https://github.com/rugonzs/FLAI/issues" target="_blank">Issue Tracker</a> â€” Report bugs</li>
              </ul>
            </div>
            <div>
              <h3>ğŸ“ˆ Technical Specs</h3>
              <ul class="feature-list">
                <li>ğŸŒŸ <strong>Version:</strong> 3.0.4 (Latest)</li>
                <li>ğŸ“ˆ <strong>Downloads:</strong> Available on PyPI</li>
                <li>âš–ï¸ <strong>License:</strong> Apache-2.0 (Enterprise-friendly)</li>
                <li>ğŸ <strong>Python:</strong> 3.9+ (Legacy support available)</li>
              </ul>
            </div>
          </div>
        </div>
      </div>
    </section>

    <footer class="footer">
      <div class="footer-content">
        <p>Â© <span id="year"></span> FLAI â€” Fairness Learning in AI | Developed by <a href="https://rubengonzalez.ai" target="_blank">RubÃ©n GonzÃ¡lez-Sendino</a></p>
        <p>
          <a href="https://github.com/rugonzs/FLAI" target="_blank">GitHub</a> Â· 
          <a href="https://pypi.org/project/flai-causal/" target="_blank">PyPI</a> Â· 
          <a href="./demo/">Demo</a> Â· 
          <a href="./documentation.html">Docs</a> Â· 
          <a href="https://rubengonzalez.ai" target="_blank">Portfolio</a>
        </p>
        <p>Research-grade fairness for production AI systems | Universidad PolitÃ©cnica de Madrid</p>
      </div>
    </footer>
  </div>
  
  <script>
    document.getElementById('year').textContent = new Date().getFullYear();
    
    // Smooth scrolling for internal links
    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
      anchor.addEventListener('click', function (e) {
        e.preventDefault();
        const target = document.querySelector(this.getAttribute('href'));
        if (target) {
          target.scrollIntoView({ behavior: 'smooth', block: 'start' });
        }
      });
    });
    
    // Intersection Observer for animations
    const observerOptions = {
      threshold: 0.1,
      rootMargin: '0px 0px -50px 0px'
    };
    
    const observer = new IntersectionObserver((entries) => {
      entries.forEach(entry => {
        if (entry.isIntersecting) {
          entry.target.classList.add('fade-in');
        }
      });
    }, observerOptions);
    
    document.querySelectorAll('.card, .section, .stat').forEach(el => {
      observer.observe(el);
    });

    // Interactive bias chart hover effects
    document.querySelectorAll('.bias-bar').forEach(bar => {
      bar.addEventListener('mouseenter', () => {
        bar.style.transform = 'scale(1.05)';
      });
      bar.addEventListener('mouseleave', () => {
        bar.style.transform = 'scale(1)';
      });
    });
  </script>
</body>
</html>