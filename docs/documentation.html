<!doctype html>
<html lang="es">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>FLAI â€” DocumentaciÃ³n Completa | API y GuÃ­as</title>
  <meta name="description" content="DocumentaciÃ³n completa de FLAI: API reference, guÃ­as de uso, ejemplos y tutoriales para detectar y mitigar sesgos algorÃ­tmicos."/>
  <link rel="stylesheet" href="./assets/styles.css" />
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700;800&display=swap" rel="stylesheet">
  
  <style>
    .toc {
      background: var(--card);
      border: 1px solid var(--border);
      border-radius: 12px;
      padding: 24px;
      margin: 24px 0;
      position: sticky;
      top: 100px;
      max-height: 70vh;
      overflow-y: auto;
    }
    
    .toc ul {
      list-style: none;
      padding: 0;
      margin: 0;
    }
    
    .toc li {
      margin: 8px 0;
    }
    
    .toc a {
      color: var(--muted);
      text-decoration: none;
      padding: 4px 8px;
      border-radius: 6px;
      transition: all 0.3s ease;
    }
    
    .toc a:hover {
      background: var(--accent-light);
      color: var(--accent);
    }
    
    .content-grid {
      display: grid;
      grid-template-columns: 250px 1fr;
      gap: 40px;
      margin-top: 40px;
    }
    
    .api-section {
      margin: 48px 0;
      padding: 32px;
      background: var(--card);
      border: 1px solid var(--border);
      border-radius: 16px;
      position: relative;
    }
    
    .api-section::before {
      content: '';
      position: absolute;
      top: 0;
      left: 0;
      right: 0;
      height: 4px;
      background: var(--gradient-hero);
      border-radius: 16px 16px 0 0;
    }
    
    .method-signature {
      background: var(--bg-secondary);
      border: 1px solid var(--border);
      border-radius: 8px;
      padding: 16px;
      margin: 16px 0;
      font-family: 'Monaco', 'Menlo', monospace;
      font-size: 0.9rem;
      overflow-x: auto;
    }
    
    .parameters {
      margin: 16px 0;
    }
    
    .parameter {
      margin: 12px 0;
      padding: 12px;
      background: var(--bg-secondary);
      border-left: 4px solid var(--accent);
      border-radius: 0 8px 8px 0;
    }
    
    .parameter-name {
      font-weight: 700;
      color: var(--accent);
      font-family: monospace;
    }
    
    .parameter-type {
      color: var(--muted);
      font-size: 0.9rem;
      font-style: italic;
    }
    
    .example-code {
      background: var(--bg-secondary);
      border: 1px solid var(--border);
      border-radius: 12px;
      padding: 20px;
      margin: 20px 0;
      overflow-x: auto;
      position: relative;
    }
    
    .example-code::before {
      content: 'ğŸ’» Ejemplo';
      position: absolute;
      top: -12px;
      left: 20px;
      background: var(--accent);
      color: white;
      padding: 4px 12px;
      border-radius: 20px;
      font-size: 0.8rem;
      font-weight: 700;
    }
    
    .returns {
      background: var(--gold-light);
      border: 1px solid var(--gold);
      border-radius: 8px;
      padding: 16px;
      margin: 16px 0;
    }
    
    .returns h4 {
      color: var(--gold);
      margin: 0 0 8px 0;
    }
    
    @media (max-width: 1024px) {
      .content-grid {
        grid-template-columns: 1fr;
      }
      
      .toc {
        position: static;
        max-height: none;
      }
    }
  </style>
</head>
<body>
  <div class="container">
    <header class="header">
      <div class="brand">ğŸ”¬ FLAI</div>
      <nav class="nav">
        <a href="./">ğŸ  Inicio</a>
        <a href="./demo/">ğŸ“Š Demo</a>
        <a href="./documentation.html">ğŸ“– Docs</a>
        <a href="https://github.com/rugonzs/FLAI" target="_blank">GitHub</a>
        <a href="https://pypi.org/project/flai-causal/" target="_blank">PyPI</a>
      </nav>
    </header>

    <section class="hero">
      <div>
        <div class="badge">ğŸ“š DocumentaciÃ³n Completa</div>
        <h1>GuÃ­a TÃ©cnica de FLAI</h1>
        <p>Referencia completa de la API, guÃ­as de instalaciÃ³n, tutoriales paso a paso y mejores prÃ¡cticas para implementar fairness en tus modelos de IA.</p>
      </div>
    </section>

    <div class="content-grid">
      <aside class="toc">
        <h3>ğŸ“‹ Ãndice</h3>
        <ul>
          <li><a href="#instalacion">ğŸš€ InstalaciÃ³n</a></li>
          <li><a href="#inicio-rapido">âš¡ Inicio RÃ¡pido</a></li>
          <li><a href="#data-class">ğŸ“Š Clase Data</a>
            <ul>
              <li><a href="#data-init">Constructor</a></li>
              <li><a href="#fairness-eqa-eqi">fairness_eqa_eqi()</a></li>
              <li><a href="#fairness-metrics">fairness_metrics()</a></li>
            </ul>
          </li>
          <li><a href="#causal-graph-class">ğŸ§  Clase CausalGraph</a>
            <ul>
              <li><a href="#causal-init">Constructor</a></li>
              <li><a href="#mitigate-edge">mitigate_edge_relation()</a></li>
              <li><a href="#mitigate-cpd">mitigate_calculation_cpd()</a></li>
              <li><a href="#generate-dataset">generate_dataset()</a></li>
              <li><a href="#inference">inference()</a></li>
            </ul>
          </li>
          <li><a href="#ejemplos">ğŸ“š Ejemplos Completos</a></li>
          <li><a href="#mejores-practicas">âœ¨ Mejores PrÃ¡cticas</a></li>
        </ul>
      </aside>

      <main>
        <section id="instalacion" class="api-section">
          <h2>ğŸš€ InstalaciÃ³n</h2>
          
          <h3>Requisitos del Sistema</h3>
          <ul>
            <li><strong>Python:</strong> >= 3.9 (recomendado 3.10+)</li>
            <li><strong>Memoria:</strong> MÃ­nimo 4GB RAM</li>
            <li><strong>Espacio:</strong> ~500MB para dependencias</li>
          </ul>

          <h3>InstalaciÃ³n desde PyPI</h3>
          <div class="example-code">
            <pre><code># VersiÃ³n mÃ¡s reciente (Python >= 3.9)
pip install flai-causal

# Para Python <= 3.9
pip install flai-causal==2.0.0

# Con dependencias opcionales para visualizaciÃ³n
pip install flai-causal[viz]</code></pre>
          </div>

          <h3>InstalaciÃ³n desde GitHub</h3>
          <div class="example-code">
            <pre><code># VersiÃ³n de desarrollo
pip install git+https://github.com/rugonzs/FLAI.git

# VersiÃ³n especÃ­fica
pip install git+https://github.com/rugonzs/FLAI.git@v3.0.4</code></pre>
          </div>

          <h3>VerificaciÃ³n de InstalaciÃ³n</h3>
          <div class="example-code">
            <pre><code>import FLAI
from FLAI import data, causal_graph
print(f"FLAI instalado correctamente. VersiÃ³n disponible.")</code></pre>
          </div>
        </section>

        <section id="inicio-rapido" class="api-section">
          <h2>âš¡ Inicio RÃ¡pido</h2>
          
          <p>Ejemplo completo en 5 minutos para detectar y mitigar sesgos:</p>

          <div class="example-code">
            <pre><code>import pandas as pd
from FLAI import data, causal_graph

# 1. Cargar y preparar datos
df = pd.read_csv('tu_dataset.csv')  # O usar pickle, parquet, etc.
flai_dataset = data.Data(df, transform=True)

# 2. Detectar sesgos con mÃ©trica bidimensional
df_fairness, datos_detalle = flai_dataset.fairness_eqa_eqi(
    features=['education', 'age'],      # Variables explicativas
    target_column='income',             # Variable objetivo
    column_filter=['gender'],           # Variable sensible
    plot=True                          # Visualizar resultados
)

print("ğŸ“Š MÃ©tricas de Fairness:")
print(df_fairness)

# 3. Crear modelo causal
flai_graph = causal_graph.CausalGraph(
    flai_dataset, 
    target='income'
)

# 4. Mitigar sesgos
flai_graph.mitigate_edge_relation(sensible_feature=['gender'])
flai_graph.mitigate_calculation_cpd(sensible_feature=['gender'])

# 5. Generar datos justos
fair_data = flai_graph.generate_dataset(
    n_samples=1000, 
    methodtype='bayes'
)

# 6. Verificar mejora
df_fairness_new, _ = fair_data.fairness_eqa_eqi(
    features=['education', 'age'],
    target_column='income',
    column_filter=['gender'],
    plot=True
)

print("âœ… DespuÃ©s de mitigaciÃ³n:")
print(df_fairness_new)</code></pre>
          </div>
        </section>

        <section id="data-class" class="api-section">
          <h2>ğŸ“Š Clase Data</h2>
          
          <p>La clase <code>Data</code> es el punto de entrada principal para el anÃ¡lisis de fairness. Encapsula un dataset y proporciona mÃ©todos para detectar y medir sesgos.</p>

          <div id="data-init">
            <h3>Constructor</h3>
            <div class="method-signature">
              <code>Data(data=None, transform=True, verbose=0)</code>
            </div>

            <div class="parameters">
              <div class="parameter">
                <div class="parameter-name">data</div>
                <div class="parameter-type">pandas.DataFrame, required</div>
                <p>Dataset a analizar. Debe contener variables categÃ³ricas y numÃ©ricas.</p>
              </div>
              
              <div class="parameter">
                <div class="parameter-name">transform</div>
                <div class="parameter-type">bool, default=True</div>
                <p>Si True, transforma automÃ¡ticamente variables categÃ³ricas a numÃ©ricas usando OrdinalEncoder.</p>
              </div>
              
              <div class="parameter">
                <div class="parameter-name">verbose</div>
                <div class="parameter-type">int, default=0</div>
                <p>Nivel de verbosidad (0=silencioso, 1=bÃ¡sico, 2=detallado).</p>
              </div>
            </div>

            <div class="example-code">
              <pre><code># Cargar datos con transformaciÃ³n automÃ¡tica
import pandas as pd
from FLAI import data

df = pd.read_csv('adult.csv')
flai_dataset = data.Data(df, transform=True, verbose=1)

# Acceder a datos transformados
print(flai_dataset.data.head())
print(f"Forma del dataset: {flai_dataset.data.shape}")

# Ver mapeo de categorÃ­as originales
print("Mapeo de categorÃ­as:", flai_dataset.map_cat)</code></pre>
            </div>
          </div>

          <div id="fairness-eqa-eqi">
            <h3>fairness_eqa_eqi()</h3>
            <p>ğŸ† <strong>MÃ©todo principal:</strong> Calcula la mÃ©trica bidimensional EQA-EQI que distingue igualdad de equidad.</p>
            
            <div class="method-signature">
              <code>fairness_eqa_eqi(features, target_column, column_filter, plot=True)</code>
            </div>

            <div class="parameters">
              <div class="parameter">
                <div class="parameter-name">features</div>
                <div class="parameter-type">list of str, required</div>
                <p>Lista de columnas que representan caracterÃ­sticas no sensibles (ej: ['education', 'age']).</p>
              </div>
              
              <div class="parameter">
                <div class="parameter-name">target_column</div>
                <div class="parameter-type">str, required</div>
                <p>Nombre de la columna objetivo/predicciÃ³n a analizar.</p>
              </div>
              
              <div class="parameter">
                <div class="parameter-name">column_filter</div>
                <div class="parameter-type">list of str, required</div>
                <p>Lista de columnas sensibles para anÃ¡lisis de fairness (ej: ['gender', 'race']).</p>
              </div>
              
              <div class="parameter">
                <div class="parameter-name">plot</div>
                <div class="parameter-type">bool, default=True</div>
                <p>Si True, genera visualizaciones automÃ¡ticas de las mÃ©tricas.</p>
              </div>
            </div>

            <div class="returns">
              <h4>ğŸ”„ Retorna</h4>
              <p><strong>tuple:</strong> (df_fairness, datos_detalle)</p>
              <ul>
                <li><strong>df_fairness:</strong> DataFrame con mÃ©tricas EQI, EQA y F para cada grupo</li>
                <li><strong>datos_detalle:</strong> DataFrame con anÃ¡lisis detallado por grupo y caracterÃ­stica</li>
              </ul>
            </div>

            <div class="example-code">
              <pre><code># Ejemplo: AnÃ¡lisis de fairness por gÃ©nero
df_f, datos_f = flai_dataset.fairness_eqa_eqi(
    features=['education'],           # Variable explicativa
    target_column='income_high',      # Variable a predecir
    column_filter=['gender'],         # Variable sensible
    plot=True                        # Mostrar grÃ¡ficos
)

print("ğŸ“Š Resultados:")
print(df_f)
# Salida esperada:
#        group     reference   EQI    EQA     F
# 0  gender_0     gender_1   -0.04  0.08  0.09

# InterpretaciÃ³n:
# EQI = -0.04: Diferencia en oportunidades (negativo = grupo 0 desfavorecido)
# EQA = 0.08:  Diferencia en resultados generales  
# F = 0.09:    Unfairness global = âˆš(EQAÂ² + EQIÂ²)</code></pre>
            </div>
          </div>

          <div id="fairness-metrics">
            <h3>fairness_metrics()</h3>
            <p>Calcula mÃ©tricas tradicionales de fairness para comparaciÃ³n con EQA-EQI.</p>
            
            <div class="method-signature">
              <code>fairness_metrics(target_column, predicted_column, columns_fair)</code>
            </div>

            <div class="parameters">
              <div class="parameter">
                <div class="parameter-name">target_column</div>
                <div class="parameter-type">str, required</div>
                <p>Columna con etiquetas verdaderas (ground truth).</p>
              </div>
              
              <div class="parameter">
                <div class="parameter-name">predicted_column</div>
                <div class="parameter-type">str, required</div>
                <p>Columna con predicciones del modelo.</p>
              </div>
              
              <div class="parameter">
                <div class="parameter-name">columns_fair</div>
                <div class="parameter-type">dict, required</div>
                <p>Diccionario especificando grupos privilegiados/no privilegiados.</p>
              </div>
            </div>

            <div class="example-code">
              <pre><code># MÃ©tricas tradicionales para comparar
metrics = flai_dataset.fairness_metrics(
    target_column='true_label',
    predicted_column='predicted_label', 
    columns_fair={
        'gender': {'privileged': 1, 'unprivileged': 0},
        'age': {'privileged': 1, 'unprivileged': 0}
    }
)

# Obtener DataFrames organizados
df_performance, df_fairness = flai_dataset.get_df_metrics(metrics)

print("ğŸ¯ MÃ©tricas de Performance:")
print(df_performance[['ACC', 'TPR', 'FPR', 'PPP']])

print("âš–ï¸ MÃ©tricas de Fairness:")
print(df_fairness[['EOD', 'DI', 'SPD', 'OD']])</code></pre>
            </div>
          </div>
        </section>

        <section id="causal-graph-class" class="api-section">
          <h2>ğŸ§  Clase CausalGraph</h2>
          
          <p>La clase <code>CausalGraph</code> implementa redes bayesianas causales para modelar y mitigar sesgos algorÃ­tmicos.</p>

          <div id="causal-init">
            <h3>Constructor</h3>
            <div class="method-signature">
              <code>CausalGraph(flai_dataset, node_edge=None, CPD=None, indepence_test=True, root_node=None, target=None, verbose=0)</code>
            </div>

            <div class="parameters">
              <div class="parameter">
                <div class="parameter-name">flai_dataset</div>
                <div class="parameter-type">FLAI.data.Data, required</div>
                <p>Instancia de la clase Data con el dataset a modelar.</p>
              </div>
              
              <div class="parameter">
                <div class="parameter-name">target</div>
                <div class="parameter-type">str, required</div>
                <p>Variable objetivo del modelo causal.</p>
              </div>
              
              <div class="parameter">
                <div class="parameter-name">node_edge</div>
                <div class="parameter-type">list of tuples, optional</div>
                <p>Lista de aristas para construir el grafo manualmente. Si None, se aprende automÃ¡ticamente.</p>
              </div>
              
              <div class="parameter">
                <div class="parameter-name">indepence_test</div>
                <div class="parameter-type">bool, default=True</div>
                <p>Si True, aplica test de independencia para validar aristas.</p>
              </div>
            </div>

            <div class="example-code">
              <pre><code># ConstrucciÃ³n automÃ¡tica del grafo
flai_graph = causal_graph.CausalGraph(
    flai_dataset=flai_dataset,
    target='income',
    verbose=1
)

# Visualizar el grafo
flai_graph.plot(directed=True)

# Ver las aristas aprendidas
print("ğŸ”— Aristas del grafo:", flai_graph.graph['model_edges'])

# ConstrucciÃ³n manual del grafo
manual_edges = [
    ('age', 'income'),
    ('education', 'income'),
    ('gender', 'education'),
    ('gender', 'income')
]

flai_graph_manual = causal_graph.CausalGraph(
    flai_dataset=flai_dataset,
    node_edge=manual_edges,
    target='income'
)</code></pre>
            </div>
          </div>

          <div id="mitigate-edge">
            <h3>mitigate_edge_relation()</h3>
            <p>ğŸ› ï¸ <strong>MitigaciÃ³n estructural:</strong> Modifica las relaciones causales para eliminar conexiones discriminatorias.</p>
            
            <div class="method-signature">
              <code>mitigate_edge_relation(sensible_feature)</code>
            </div>

            <div class="parameters">
              <div class="parameter">
                <div class="parameter-name">sensible_feature</div>
                <div class="parameter-type">list of str, required</div>
                <p>Lista de variables sensibles cuyas relaciones causales se van a mitigar.</p>
              </div>
            </div>

            <div class="returns">
              <h4>ğŸ”„ Retorna</h4>
              <p><strong>list:</strong> Lista de aristas del grafo mitigado</p>
            </div>

            <div class="example-code">
              <pre><code># Antes de la mitigaciÃ³n
print("ğŸ“Š Aristas originales:")
print(flai_graph.graph['model_edges'])

# Mitigar relaciones de variables sensibles
mitigated_edges = flai_graph.mitigate_edge_relation(
    sensible_feature=['gender', 'age']
)

print("âœ… Aristas despuÃ©s de mitigaciÃ³n:")
print(mitigated_edges)

# Visualizar cambios
flai_graph.plot(directed=True)

# Ejemplo de transformaciÃ³n:
# Antes: [('gender', 'income'), ('age', 'income'), ('education', 'income')]
# DespuÃ©s: [('education', 'income'), ('gender', 'education'), ('age', 'education')]
# Las variables sensibles ya no afectan directamente al resultado</code></pre>
            </div>
          </div>

          <div id="mitigate-cpd">
            <h3>mitigate_calculation_cpd()</h3>
            <p>ğŸ“Š <strong>MitigaciÃ³n probabilÃ­stica:</strong> Ajusta las tablas de probabilidad condicional para reducir sesgos.</p>
            
            <div class="method-signature">
              <code>mitigate_calculation_cpd(sensible_feature, fix_proportion=True, verbose=0)</code>
            </div>

            <div class="parameters">
              <div class="parameter">
                <div class="parameter-name">sensible_feature</div>
                <div class="parameter-type">list of str, required</div>
                <p>Variables sensibles cuyas distribuciones se van a ajustar.</p>
              </div>
              
              <div class="parameter">
                <div class="parameter-name">fix_proportion</div>
                <div class="parameter-type">bool, default=True</div>
                <p>Si True, iguala las proporciones de variables sensibles.</p>
              </div>
            </div>

            <div class="example-code">
              <pre><code># Aplicar mitigaciÃ³n probabilÃ­stica
flai_graph.mitigate_calculation_cpd(
    sensible_feature=['gender', 'age'],
    fix_proportion=True,
    verbose=1
)

# Comparar probabilidades antes y despuÃ©s
print("ğŸ“Š Inferencia antes de mitigaciÃ³n:")
original_inference = flai_graph.inference(
    variables=['gender', 'income'], 
    evidence={}
)
print(original_inference)

print("âœ… Inferencia despuÃ©s de mitigaciÃ³n:")
# Ahora las probabilidades son iguales independientemente del gÃ©nero</code></pre>
            </div>
          </div>

          <div id="generate-dataset">
            <h3>generate_dataset()</h3>
            <p>ğŸ”„ <strong>GeneraciÃ³n de datos justos:</strong> Crea datasets sintÃ©ticos libres de sesgo usando el modelo mitigado.</p>
            
            <div class="method-signature">
              <code>generate_dataset(n_samples=1000, methodtype='bayes', verbose=0)</code>
            </div>

            <div class="parameters">
              <div class="parameter">
                <div class="parameter-name">n_samples</div>
                <div class="parameter-type">int, default=1000</div>
                <p>NÃºmero de muestras a generar.</p>
              </div>
              
              <div class="parameter">
                <div class="parameter-name">methodtype</div>
                <div class="parameter-type">str, default='bayes'</div>
                <p>MÃ©todo de muestreo ('bayes', 'rejection', etc.).</p>
              </div>
            </div>

            <div class="returns">
              <h4>ğŸ”„ Retorna</h4>
              <p><strong>FLAI.data.Data:</strong> Nueva instancia con datos sintÃ©ticos justos</p>
            </div>

            <div class="example-code">
              <pre><code># Generar datos justos
fair_data = flai_graph.generate_dataset(
    n_samples=5000,
    methodtype='bayes',
    verbose=1
)

print(f"ğŸ“ˆ Dataset justo generado: {fair_data.data.shape}")
print(fair_data.data.head())

# Verificar que el sesgo se ha eliminado
df_fair, _ = fair_data.fairness_eqa_eqi(
    features=['education'],
    target_column='income',
    column_filter=['gender'],
    plot=True
)

print("âœ… MÃ©tricas en datos justos:")
print(df_fair)
# Esperado: EQI â‰ˆ 0, EQA â‰ˆ 0, F â‰ˆ 0

# Usar para entrenar nuevos modelos
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split

X = fair_data.data.drop('income', axis=1)
y = fair_data.data['income']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
model = RandomForestClassifier()
model.fit(X_train, y_train)</code></pre>
            </div>
          </div>

          <div id="inference">
            <h3>inference()</h3>
            <p>ğŸ”® Realiza inferencia bayesiana en el modelo causal.</p>
            
            <div class="method-signature">
              <code>inference(variables, evidence={}, verbose=0)</code>
            </div>

            <div class="example-code">
              <pre><code># Inferencia simple
result = flai_graph.inference(
    variables=['gender', 'income'],
    evidence={}
)
print("ğŸ”® Probabilidades conjuntas:")
print(result)

# Inferencia condicional
result_conditional = flai_graph.inference(
    variables=['income'],
    evidence={'gender': 1, 'education': 3}
)
print("ğŸ¯ P(income | gender=1, education=3):")
print(result_conditional)</code></pre>
            </div>
          </div>
        </section>

        <section id="ejemplos" class="api-section">
          <h2>ğŸ“š Ejemplos Completos</h2>

          <h3>ğŸ¯ Caso 1: Dataset Adult (Census Income)</h3>
          <div class="example-code">
            <pre><code># Pipeline completo para dataset Adult
import pandas as pd
from FLAI import data, causal_graph
import matplotlib.pyplot as plt

# 1. Cargar datos
df = pd.read_csv('adult.csv')
print(f"ğŸ“Š Dataset cargado: {df.shape}")

# 2. Preparar con FLAI
flai_dataset = data.Data(df, transform=True)

# 3. AnÃ¡lisis inicial de fairness
print("ğŸ” AnÃ¡lisis inicial de sesgos...")
df_original, _ = flai_dataset.fairness_eqa_eqi(
    features=['education-num', 'age'],
    target_column='income',
    column_filter=['sex'],
    plot=True
)
print("ğŸ“ˆ Fairness original:")
print(df_original)

# 4. Construir modelo causal
flai_graph = causal_graph.CausalGraph(
    flai_dataset, 
    target='income',
    verbose=1
)

# 5. Aplicar mitigaciÃ³n completa
print("ğŸ› ï¸ Aplicando mitigaciÃ³n...")
flai_graph.mitigate_edge_relation(sensible_feature=['sex', 'age'])
flai_graph.mitigate_calculation_cpd(sensible_feature=['sex', 'age'])

# 6. Generar datos justos
fair_data = flai_graph.generate_dataset(n_samples=2000)

# 7. Verificar mejora
df_mitigated, _ = fair_data.fairness_eqa_eqi(
    features=['education-num', 'age'],
    target_column='income',
    column_filter=['sex'],
    plot=True
)
print("âœ… Fairness despuÃ©s de mitigaciÃ³n:")
print(df_mitigated)

# 8. ComparaciÃ³n visual
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))

# Plot original
original_values = df_original[['EQI', 'EQA', 'F']].values[0]
ax1.bar(['EQI', 'EQA', 'F'], original_values, color=['red', 'orange', 'darkred'])
ax1.set_title('Original Dataset')
ax1.set_ylabel('Unfairness Score')

# Plot mitigated  
mitigated_values = df_mitigated[['EQI', 'EQA', 'F']].values[0]
ax2.bar(['EQI', 'EQA', 'F'], mitigated_values, color=['green', 'lightgreen', 'darkgreen'])
ax2.set_title('After FLAI Mitigation')
ax2.set_ylabel('Unfairness Score')

plt.tight_layout()
plt.show()

print(f"ğŸ¯ Mejora en Fairness Global: {original_values[2]:.3f} â†’ {mitigated_values[2]:.3f}")</code></pre>
          </div>

          <h3>âš–ï¸ Caso 2: Dataset COMPAS (Recidivism)</h3>
          <div class="example-code">
            <pre><code># AnÃ¡lisis de algoritmos de justicia penal
import pandas as pd
from FLAI import data, causal_graph

# Cargar datos COMPAS
df_compas = pd.read_csv('compas-scores.csv')

# Preparar datos
flai_compas = data.Data(df_compas, transform=True)

# AnÃ¡lisis especÃ­fico por raza
df_racial_bias, _ = flai_compas.fairness_eqa_eqi(
    features=['priors_count', 'age'],
    target_column='two_year_recid',
    column_filter=['race'],
    plot=True
)

print("âš–ï¸ Sesgo racial en COMPAS:")
print(df_racial_bias)

# Construir modelo especÃ­fico para justicia
compas_graph = causal_graph.CausalGraph(
    flai_compas,
    target='two_year_recid',
    verbose=1
)

# MitigaciÃ³n enfocada en raza
compas_graph.mitigate_edge_relation(sensible_feature=['race'])
compas_graph.mitigate_calculation_cpd(sensible_feature=['race'])

# Evaluar impacto
fair_compas = compas_graph.generate_dataset(n_samples=1000)
df_compas_fair, _ = fair_compas.fairness_eqa_eqi(
    features=['priors_count', 'age'],
    target_column='two_year_recid', 
    column_filter=['race'],
    plot=True
)

print("âœ… COMPAS despuÃ©s de mitigaciÃ³n:")
print(df_compas_fair)</code></pre>
          </div>
        </section>

        <section id="mejores-practicas" class="api-section">
          <h2>âœ¨ Mejores PrÃ¡cticas</h2>

          <h3>ğŸ¯ PreparaciÃ³n de Datos</h3>
          <ul>
            <li><strong>Limpieza previa:</strong> Elimina valores faltantes y outliers antes de usar FLAI</li>
            <li><strong>Variables categÃ³ricas:</strong> AsegÃºrate de que estÃ©n bien codificadas (usa <code>transform=True</code>)</li>
            <li><strong>TamaÃ±o mÃ­nimo:</strong> Datasets con al menos 1000 registros dan mejores resultados</li>
            <li><strong>Balance de clases:</strong> Verifica que no haya clases extremadamente desbalanceadas</li>
          </ul>

          <h3>ğŸ“Š InterpretaciÃ³n de MÃ©tricas</h3>
          <div class="example-code">
            <pre><code># GuÃ­a de interpretaciÃ³n
def interpretar_fairness(df_fairness):
    """Interpreta automÃ¡ticamente los resultados de fairness"""
    for _, row in df_fairness.iterrows():
        eqi, eqa, f = row['EQI'], row['EQA'], row['F']
        
        print(f"ğŸ” Grupo: {row['group']} vs {row['reference']}")
        
        # InterpretaciÃ³n EQI (Equidad)
        if abs(eqi) < 0.02:
            print("  âœ… EQI: Equidad excelente")
        elif abs(eqi) < 0.05:
            print("  âš ï¸ EQI: Ligera inequidad")
        else:
            print("  âŒ EQI: Inequidad significativa")
            
        # InterpretaciÃ³n EQA (Igualdad)  
        if abs(eqa) < 0.02:
            print("  âœ… EQA: Igualdad excelente")
        elif abs(eqa) < 0.05:
            print("  âš ï¸ EQA: Ligera desigualdad")
        else:
            print("  âŒ EQA: Desigualdad significativa")
            
        # RecomendaciÃ³n
        if f < 0.03:
            print("  ğŸ¯ RecomendaciÃ³n: Dataset justo, no necesita mitigaciÃ³n")
        elif f < 0.08:
            print("  ğŸ”§ RecomendaciÃ³n: Considerar mitigaciÃ³n ligera")
        else:
            print("  ğŸš¨ RecomendaciÃ³n: MitigaciÃ³n urgente necesaria")
        print()

# Uso
interpretar_fairness(df_fairness)</code></pre>
          </div>

          <h3>ğŸ› ï¸ Estrategias de MitigaciÃ³n</h3>
          <ul>
            <li><strong>MitigaciÃ³n suave:</strong> Para F entre 0.03-0.08, usa solo <code>mitigate_calculation_cpd()</code></li>
            <li><strong>MitigaciÃ³n completa:</strong> Para F > 0.08, combina ambos mÃ©todos</li>
            <li><strong>ValidaciÃ³n cruzada:</strong> Siempre valida en datos de test independientes</li>
            <li><strong>Trade-offs:</strong> Monitorea accuracy vs fairness para encontrar el balance Ã³ptimo</li>
          </ul>

          <h3>ğŸš€ OptimizaciÃ³n de Performance</h3>
          <div class="example-code">
            <pre><code># ConfiguraciÃ³n para datasets grandes
import warnings
warnings.filterwarnings('ignore')  # Silenciar warnings no crÃ­ticos

# Para datasets > 10K registros
flai_dataset = data.Data(
    large_df.sample(5000),  # Muestreo para acelerar
    transform=True,
    verbose=0  # Reducir output
)

# ConstrucciÃ³n rÃ¡pida de grafo
flai_graph = causal_graph.CausalGraph(
    flai_dataset,
    target='label',
    indepence_test=False,  # Omitir test para acelerar
    verbose=0
)

# GeneraciÃ³n eficiente de datos
fair_data = flai_graph.generate_dataset(
    n_samples=min(1000, len(original_data)),  # Limitar tamaÃ±o
    methodtype='bayes'
)</code></pre>
          </div>

          <h3>âš ï¸ Limitaciones y Consideraciones</h3>
          <ul>
            <li><strong>Causalidad vs CorrelaciÃ³n:</strong> FLAI asume relaciones causales, valida con conocimiento del dominio</li>
            <li><strong>Variables proxy:</strong> Cuidado con variables que indirectamente codifican informaciÃ³n sensible</li>
            <li><strong>Contexto legal:</strong> Siempre consulta regulaciones locales sobre fairness algorÃ­tmica</li>
            <li><strong>ValidaciÃ³n humana:</strong> Los resultados deben ser validados por expertos en el dominio</li>
          </ul>

          <div class="research-highlight">
            <h4>ğŸ“š Recursos Adicionales</h4>
            <ul>
              <li><a href="https://github.com/rugonzs/FLAI" target="_blank">ğŸ“ Repositorio GitHub</a> - CÃ³digo fuente y ejemplos</li>
              <li><a href="https://www.sciencedirect.com/science/article/abs/pii/S0952197624021389" target="_blank">ğŸ“„ Paper Principal</a> - Fundamentos teÃ³ricos</li>
              <li><a href="../demo/" target="_blank">ğŸ§ª Demo Interactiva</a> - Prueba FLAI en tu navegador</li>
              <li><a href="mailto:rubo.g@icloud.com">âœ‰ï¸ Contacto Directo</a> - Soporte del desarrollador</li>
            </ul>
          </div>
        </section>
      </main>
    </div>

    <footer>
      <p>Â© <span id="year"></span> FLAI Documentation | Desarrollado por <a href="https://rubengonzalez.ai" target="_blank">RubÃ©n GonzÃ¡lez-Sendino</a></p>
      <p>
        <a href="./">ğŸ  Inicio</a> Â· 
        <a href="./demo/">ğŸ“Š Demo</a> Â· 
        <a href="https://github.com/rugonzs/FLAI" target="_blank">GitHub</a> Â· 
        <a href="https://pypi.org/project/flai-causal/" target="_blank">PyPI</a>
      </p>
    </footer>
  </div>

  <script>
    document.getElementById('year').textContent = new Date().getFullYear();
    
    // Smooth scrolling para TOC
    document.querySelectorAll('.toc a').forEach(link => {
      link.addEventListener('click', function(e) {
        e.preventDefault();
        const target = document.querySelector(this.getAttribute('href'));
        if (target) {
          target.scrollIntoView({ behavior: 'smooth', block: 'start' });
        }
      });
    });

    // Highlight TOC item activo
    const sections = document.querySelectorAll('.api-section');
    const tocLinks = document.querySelectorAll('.toc a');

    const observer = new IntersectionObserver((entries) => {
      entries.forEach(entry => {
        if (entry.isIntersecting) {
          const id = entry.target.id;
          tocLinks.forEach(link => {
            link.style.color = link.getAttribute('href') === `#${id}` ? 'var(--accent)' : 'var(--muted)';
            link.style.background = link.getAttribute('href') === `#${id}` ? 'var(--accent-light)' : 'transparent';
          });
        }
      });
    }, { rootMargin: '-100px 0px -60% 0px' });

    sections.forEach(section => observer.observe(section));

    // Animaciones
    const animationObserver = new IntersectionObserver((entries) => {
      entries.forEach(entry => {
        if (entry.isIntersecting) {
          entry.target.style.animation = 'fadeInUp 0.6s ease-out';
        }
      });
    }, { threshold: 0.1 });
    
    document.querySelectorAll('.api-section').forEach(el => {
      animationObserver.observe(el);
    });
  </script>
</body>
</html>